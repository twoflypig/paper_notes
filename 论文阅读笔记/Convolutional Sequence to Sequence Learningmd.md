之先流行的方法是使用RNN去处理输入序列到一个可变长度的输出序列。我们引入了一个完全基于CNN的结构。与RNN相比，在所有元素上的计算在训练是可以做到并行处理，并且优化时更加简单，因为非线性单元是固定的，输入长度也是独立的。我们使用gated linear units decoder layer 去消除梯度传播并且我们队每个decoder layer都装备了一个attention。

