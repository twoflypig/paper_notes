# Abstract

基于文本抽取的总结是有缺陷的，但是生成风格的抽象方法证明是很有挑战的。在本工作中，我们提出一个**数据驱动的**文本总结。这个模型利用局部的attention，依赖输入句子上产生总结。

*数据集*: DUC-2004

# 1 Introduction

总结的目的就是去阐述一个输入文本的浓缩表达，这个表达能够捕获原始的核心含义。大多数成功的总结系统利用的是裁剪和缝合文本部分来产生一个浓缩的版本。相反的，抽象的总结尝试产生一个自下而上的总结，包括可能不是原始一部分的方面。(就是说原本的方法只是对文本内进行裁剪，而抽象应该是一个自下而上概括的总结)

我们关注于句子级别的总结。而这方面其他的大部分工作都是基于删除的句子压缩技术，还可以用例如改写，生成和重新排序。过去的方法把这个抽象总结的问题建模为对输入句子进行语义限制的或者句法限制的转换。

而我们自己完全使用数据驱动的方法来生成抽象总结。我们的编码器用的是基于attention的 Bahdanau,它会学习在输入文本的一个隐含软对齐来帮助总结。关键的是编码器和生成模型都是联合训练的。我们的模型合并了一个和beam-search一样的额外特征来建模抽取的元素;

这个方法要求更少的语义信息,此系统没有对生成总结的词汇表假设所以能够在任何文件总结上使用

# 2 Background

句子总结，假设输出仍然来自输入的词汇表，与机器翻译任务不同，假定输出长度N是固定的，在生成之前系统是知道总结的长度,由一个开始标志 <  S>

# 3 Model

网络包括一个神经概率语言模型和一个编码器，作为一个条件总结模型

## 3.1 Neural Language Model

我们的参数化的核心是一个评估上下文中下一个词概率的语言模型。语言模型采用标准的前向神经网络语言模型

Bag of words.即把一句话分词，然后对词进行编号，这样根据编码就可以把一句话转换为一个向量了

