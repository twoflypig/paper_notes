# Prefix

翻译自博客 :http://karpathy.github.io/2015/05/21/rnn-effectiveness/

# Character-Level Language Models

我们已经知道了RNN的是啥，为啥这么好，以及怎么工作的。下面我们会给出一个具体的例子。例子的目标是:给RNN一堆文本并且要求给定之前字符的情况下，去建立序列中下一个字符的分布概率。这就允许我们生成下一个新的字符at a time

假定我们有4个可能的字符 helo，并且想让RNN训练一个"hello"。这个训练序列事实上是4个分离的训练样本:1.给定"h"的情况下下一个词应该是"e"。2.给定上下文"he"的情况下下一个字应该是"I".3.给定"hel"的情况下下一个词应该是l。4给定"hell"的情况下应该是"o"

具体来说，给每个字符进行1-of-k编码，然后输入step函数。那么我们将会观察到一个4维的输出向量(每个单词一个维度),这个向量我们解释为RNN当前对序列中接下来的每个字符的置信度。

![图](charseq.jpeg)

*这是一个4维度的输出输入RNN，隐藏层为3个单元(理解为每个维度就是一个神经元输出)。这个图标展示了当我们给RNN输入hell时整个网络的激活状态。输出层包含RNN对每个字符(h,e,l,o)的置信度。我们想要绿色的数值变大，红色的数值变小*

例如，当神经网络第一次看到字符"h"时，RNN对下一个字符为"h"的置信度为1,"e"为2.2,"l"为-3,"o"为4,1.因为在我们的训练数据中(字符"hello")下一个正确的字符应该是"e"，所以我们想要提高"e"的置信度而降低其他的字符的置信度。同样的，我们对4个time step中的每一步都有一个希望网络赋值更高的置信度的期望的目标。因为RNN包含微分操作(意思是结构上是可微的？)我们就可以运行BP算法来指出我们每个参数的权值的调整方向来增加正确目标的分数(绿色加粗部分)。我们能够执行一个参数更新，在梯度方向改变一下权值。如果我们在参数更新完成后输入相同的数据就会发现正确的字符的分数会更高，并且不正确的字符的分数会更低。我们然后重复这个过程多次知道网络收敛并且网络的预测值最终和训练数据正确字符保持一致。

