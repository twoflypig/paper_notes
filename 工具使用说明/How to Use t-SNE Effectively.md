# Notice

[tensorboard上面的文章](http://distill.pub/2016/misread-tsne/ )的笔记

2017年7月11日18:57:32

修改版本:v1

# 正文

T-SNE用于高维度的数据的降维，广泛应用在机器学习领域。虽然降维后的图像很吸引人，但是图像可能会让人误解。本文的目的就是澄清一些普遍的误解。

在开始之前，如果还没有遇到过T-SNE，你需要知道他的背后的数学原理(TODO).T-SNE是非线性的并且用来强调数据，在不同的领域执行不同的转换。这些不同会可能成为误解的根源

t-SNE第二个特点就是一个可调的参数,perlexity,是用来平衡局部和全局两个方面的注意力。这个参数在某种意义上，就是对于每个点的临近点个数的猜测。原始的论文指出这个值在5-50之间。但是其实不止这么简单，t-SNE算法在一系列运行后会产生不同的输出，例如，在优化过程中额外的超参数。

# 1.Those hyperparameters really matter

以两类不同的数据开始，为了简单化，我们仅在2维上表示。左图第一张是原始图，右边5张是tsne的不同参数的图

(在原文中看图,自己观察的结果就是，在参数值为2的时候，原本线性可分的两个类，变成了线性不可分，然后参数大了后，又变成线性可分，在参数很大的时候，就是两个类别的点相互混在了一起)

在5-50的参数范围，形状非常不同。在参数的值超过了50时，事情开始有点怪异。在参数值为2的时候，局部的变化占据主流。在图像的参数达到100时，类都混在了一起，阐明了一个缺点:为了让算法能够正常的工作，参数应该比数据点的数目小。否则在实际中就会出现意外的行为。

上述的图在学习参数=10的情况下进行了5000次迭代，并且在5000次时达到了平稳的状态。这些值会造成怎样的不同？在我们的实验中，最重要的就是在达到平稳状态前一直迭代。

(第二幅图)

上述的5个图是在相同的参数(perplexity)下进行不同的迭代。刚开头4个在达到平稳前就停止了迭代。如果你看到t-SNE的形状太奇怪，就可能是停止迭代的太早了。注意：不同数据的迭代次数可能不一样！

由一个自然的问题就是，是否相同的参数在不同的runs后会产生相同的结果。在通常情况下，大量的运行会给出相同的整体形状。然而对于确定的数据集，在不同的运行后会产生明显不同的图。下文中指定运行迭代为5000次。

# 2.Cluster sizes in a t-SNE plot mean nothing

不同大小不同分布的两个类的情况。

(图三)

表现的结果为，在t-SNE的结果中两个类都是相同的大小(初始是蓝色稀疏，黄色稠密).  **t-SNE采用距离的记号去表示在数据集中的局部稠密的分布** 。因此，与稀疏的数据相比，它会自然的拓展稠密的类，evening out (平衡)类的尺寸。确切的说，这和普通的事实不同，这个事实是任何维度的降维都会导致距离的扭曲。相反的，**密度均衡** 就是t-SNE的一个设计和特性。

# 3.类之间的距离可能是无意义的

# 4.随机的噪声看起来并不总是随机的

低的参数值(perplex)通常会使得图像呈现一段段线条，但是在本例子中缺是一个随机值！因为高纬度的数据是平坦分布的！

# 5.你有时的确会看到一些形状

低参数值情况下，会出现一些聚集的现象。

在两条长长的类时，结果也是同样类似的长条，但是直线会变成一点点弯曲。是因为t-SNE会尝试去拓宽稠密的数据区域

The reason is that, as usual, t-SNE tends to expand denser regions of data. Since the middles of the clusters have less empty space around them than the ends, the algorithm magnifies them.

# 6.For topology, you may need more than one plot

有时你可能需要从t-SNE的图中读取拓扑信心，你需要多用几个参数才能看出来

# 7 conclusion

最后结果的几个图很有意思！