# Notice

[tensorboard上面的文章](http://distill.pub/2016/misread-tsne/ )的笔记

2017年7月11日18:57:32

修改版本:v1

# 正文

T-SNE用于高维度的数据的降维，广泛应用在机器学习领域。虽然降维后的图像很吸引人，但是图像可能会让人误解。本文的目的就是澄清一些普遍的误解。

在开始之前，如果还没有遇到过T-SNE，你需要知道他的背后的数学原理(TODO).T-SNE是非线性的并且用来强调数据，在不同的领域执行不同的转换。这些不同会可能成为误解的根源

t-SNE第二个特点就是一个可调的参数,perlexity,是用来平衡局部和全局两个方面的注意力。这个参数在某种意义上，就是对于每个点的临近点个数的猜测。原始的论文指出这个值在5-50之间。但是其实不止这么简单，t-SNE算法在一系列运行后会产生不同的输出，例如，在优化过程中额外的超参数。

# 1.Those hyperparameters really matter

以两类不同的数据开始，为了简单化，我们仅在2维上表示。左图第一张是原始图，右边5张是tsne的不同参数的图

(在原文中看图,自己观察的结果就是，在参数值为2的时候，原本线性可分的两个类，变成了线性不可分，然后参数大了后，又变成线性可分，在参数很大的时候，就是两个类别的点相互混在了一起)

在5-50的参数范围，形状非常不同。在参数的值超过了50时，事情开始有点怪异。在参数值为2的时候，局部的变化占据主流。在图像的参数达到100时，类都混在了一起，阐明了一个缺点:为了让算法能够正常的工作，参数应该比数据点的数目小。否则在实际中就会出现意外的行为。

上述的图在学习参数=10的情况下进行了5000次迭代，并且在5000次时达到了平稳的状态。这些值会造成怎样的不同？在我们的实验中，最重要的就是在达到平稳状态前一直迭代。

(第二幅图)

上述的5个图是在相同的参数(perplexity)下进行不同的迭代。刚开头4个在达到平稳前就停止了迭代。如果你看到t-SNE的形状太奇怪，就可能是停止迭代的太早了。注意：不同数据的迭代次数可能不一样！

由一个自然的问题就是，是否相同的参数在不同的runs后会产生相同的结果。在通常情况下，大量的运行会给出相同的整体形状。然而对于确定的数据集，在不同的运行后会产生明显不同的图。下文中指定运行迭代为5000次。

# 2.Cluster sizes in a t-SNE plot mean nothing

